
1. corpus/
Shows the original state of the corpus, the text files I generated or found, and the processed, clustered CSV version of the corpus generated by the final code.
	
	•	1.1 raw_corpus/ – Original French texts used for analysis (unaltered source files).
	•	1.2 processed/ – Text files, and fully processed and cleaned CSVs.

2. scripts/

Contains all scripts completed, as well as some experimental productions of the scripts.
	
	•	2.1 entity_clustering_large/ – Code, CSS, and outputs for the first successful (large) entity cluster.
	•	2.2 entity_clustering_small/ – Code and outputs for the first small-scale cluster experiment.
	•	2.3 sentence_level_clustering/ – Sentence-level clustering code and related assets. All of these include original tripartite codes used to conduct analyses.
	
	•	2.4 final_code/ – Entity-centric semantic analysis code with normalisation, clustering, and word cloud capability. Along with analysable version of corpus. Ready to be run.
	
	•	2.5 topic_modeling_attempts/ – Early or abandoned topic modeling scripts and outputs.
	•	2.6 topic_modelling_attempts/ – Attempts at topic modelling with different services.
	•	2.7 wordcloud_attempts/ – Failed or preliminary word cloud experiments.
	•	2.8 scratch_data/ – Unsorted produced CSVs, partial datasets, and false starts.
	•	2.9 scripts_process/ – Old scripts which show early evolution of the final code, the process from chunk clustering to sentence clustering and introduction of KMeans and TF-IDF, shows some CSVs as well.

3. visualizations/
	
	•	3.1 wordclouds/ – All generated word clouds used for interpretation.

4. docs/
Project documentation and narrative material.
	
	•	4.1 blogpost/ – Blog or explanatory write-ups discussing the methodology or findings.

5. README.md

Overview of the project structure, purpose, and contents.
